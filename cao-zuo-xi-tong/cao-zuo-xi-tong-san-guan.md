# 操作系统三观

&lt;操作系统三观&gt;一本免费的教科书 , 当然也可以购买纸质或PDF , 当前版本为0.91 .

官网 : [http://pages.cs.wisc.edu/~remzi/OSTEP/](http://pages.cs.wisc.edu/~remzi/OSTEP/)

三观的三个部分 : 虚拟化 , 并发 , 持久性 .

### **Intro介绍**

完整目录 : [http://pages.cs.wisc.edu/~remzi/OSTEP/toc.pdf](http://pages.cs.wisc.edu/~remzi/OSTEP/toc.pdf)

介绍 : [http://pages.cs.wisc.edu/~remzi/OSTEP/intro.pdf](http://pages.cs.wisc.edu/~remzi/OSTEP/intro.pdf)

如果你已经对计算机操作系统有一定的了解 , 那么当一个计算机程序运行时 , 你的脑子里应该对这个过程有一定的概念了 . 如果没有了解 , 那这本书\(以及相应方面的内容\)对你来说可能是很难理解的 . 因此找些必要的相关知识背景的书来给你后续阅读此书做铺垫吧 , 这里推荐了 : 几个作者 , Patt/Patel , Bryant/O’Hallaron , 搜索到了他们的书 :

&lt;计算机系统概论&gt;

&lt;深入理解计算机系统&gt;

那么程序运行时会发生什么呢?

一个正在运行中的程序做的事情很简单 : 执行指令 , 每秒钟约百万次\(现今约百亿\) . 处理器从存储器中取出指令 , 进行解码\(即让机器知道程序要干什么——机器码\) , 然后去执行指令\(即让程序去做它应该要做的事情 , 比如将两个数加在一起 , 访问内存 , 状态检测 , 功能跳转等等\) . 当指令执行完毕 , 处理器将跳转到下一个指令 , 后面还有更多 , 直到程序最终完成 .

至此 , 我们只是简单的描述了一下冯诺依曼模型的基本运算 . 听起来很简单 , 但是这里 , 我们要学习的不是这些 , 许多在程序运行时我们看不见的东西，正是这些看不见的东西让操作系统更加的易于使用 , 这才是我们要讨论的 .

> **关键问题 - **如何虚拟化资源
>
> 在本书中我们围绕的一个简单的中心问题就是 : 操作系统如何虚拟化资源 ? 这就是我们的问题的核心 . 为什么这不是操作系统\(OS\)的主要问题 , 答案应该很明显 : 它只是让操作系统易于使用 . 因此 , 我们的焦点是 : 操作系统是通过什么机制和策略实现虚拟化的 ? 操作系统是怎样运行的如此高效 ? 又需要什么样的硬件支持呢 ?
>
> 我们说"问题的关键" , 正如盒子里的阴影部分 , 我们正试着找到在构建操作系统中的一种解决具体问题的方法 . 因此 , 在这个特定主题的书里 , 你也许会发现一个或者更多高于中心问题的难题 . 当然 , 在本章的小节中 , 会给出目前的解决方案 , 或者至少是解决问题的关键点 .

有一个软件的主体 , 实际上 ,  它是为了让程序易于运行\(就是让你感觉在同一时间运行了很多东西\) , 让程序共享内存 , 能够与设备交互 , 以及许多其他的功能 . 这个软件的主体就被称为**操作系统** . 它负责确保操作系统以易于使用的方式来正确高效的运行 .

操作系统运行的主要方式就是通过我们称之为虚拟化的一个通用技术 . 也就是说 , 操作系统掌握着物理资源\(如处理器,内存,磁盘\)并将它转化为更加比原来更高效 , 普遍 , 易于使用的虚拟形式 . 因此 , 我们更偏向于把操作系统当做一个虚拟机 .

当然，为了让用户能告知OS做什么从而去使用虚拟机器的资源（比如运行一个程序，或分配内存，或者读取一个文件），OS提供了一些供用户调用的接口。实际上一个典型的操作系统，是开放几百个系统调用给应用程序的。因为OS提供的这些调用，沟通内存和设备，和其他一些相关的东西，有时我们也可以说OS为应用程序提供了一个标准库。

最后 , 因为虚拟化让许多程序得以运行\(共享CPU\) , 许多程序可以同时访问他们自己的指令和数据\(共享内存\) , 许多程序连接到设备\(共享磁盘等等\) , 所以OS有时也被认为是一个资源管理器 . CPU , 内存和磁盘都是系统的资源 , 他们也是操作系统管理的那些资源中的一部分 , 不停地做着高效的或者是公平的或者是其他很多预想可能会有的事情 . 懂得这些操作系统的成员一些会更好 . 来看看一些例子 .

```c
#include <stdio.h>
#include <stdlib.h>
#include "common.h"

int main(int argc, char *argv[]) {
    if (argc != 2) {
    fprintf(stderr, "usage: cpu <string>\n");
    exit(1);
    }
    char *str = argv[1];

    while (1) {
    printf("%s\n", str);
    Spin(1);
    }
    return 0;
}
```

这是一个循环打印代码的例子 .

#### 虚拟化CPU

前面的代码是我们的第一个程序 , 它所做的事情并不多 . 实际上 , 它所做的所有的事情只有一件 , 就是调用Spin\(\) . 它所做的是重复的判断时间并且每隔一秒执行一次 , 打印出来的字符就是用户在命令行里面传入的 , 并且一直执行下去 .

以cpu.c保存该代码并且在一个系统上用单处理器\(也就是所谓的CPU\)编译执行 :

```
gcc -o cpu cpu.c -Wall
./cpu "A"
A
A
A
A
ˆC
```

程序重复的检查时间 , 每当一秒钟过去 , 系统就开始执行程序 . 每当一秒钟过去 , 代码便打印用户输入的字符\(如字母“A”\) . 这个程序会一直执行这 , 只有按下"Control-c"\(Unix类系统前台运行程序的终止方法\)才能终止 . 现在 , 让我们再跑一次程序 , 但是这次我们用相同的程序运行一些不同的例子 :

```
prompt> ./cpu A & ; ./cpu B & ; ./cpu C & ; ./cpu D &
[1] 7353
[2] 7354
[3] 7355
[4] 7356
A
B
D
C
A
B
D
C
A
C
B
D
...
```

同时运行多个程序 .

现在开始变得有点意思了 . 尽管我们只有一个处理器 , 但是不知道为什么 , 这四个进程看起来似乎时同时进行的 . 这个神奇的过程是怎么产生的呢 ? 实际上由于硬件的支持 , 操作系统让我们产生了一种错觉——系统拥有大量的虚拟CPU . 将单个CPU\(或者小的一组\)转变成似乎时无限多个CPU , 从而让多个程序似乎可以同步运行 , 这就是我们所说的虚拟化CPU , 也是本书第一个主要部分的重点 , 虚拟化 .

当然 , 启动进程 , 终止进程 , 或者告诉操作系统运行哪个进程 , 需要有一些接口能让我们将目的告知操作系统\(OS\) . 在整本书中都会讨论这些接口 , 它们就是用户与操作系统交互的主要途径 .

也许你已经注意到了 , 这种一次运行多个进程的能力带来了一系列新的问题 . 比如 , 如果两个程序要在一个特定的时间运行 , 应该运行哪个 ? OS的一种策略回答了这个问题 . 操作系统中采用各种策略来应对很多不同场景的不同类型的问题 . 因此 , 我们将要通过学习这些策略来了解操作系统所采用的基础机制\(比如同步运行多个程序的能力\) . 所以 , OS的角色就是作为一个资源管理器 .

#### 虚拟内存

```c
#include <unistd.h>
#include <stdio.h>
#include <stdlib.h>
#include <assert.h>
#include "common.h"

int
main(int argc, char *argv[])
{
    if (argc != 2) { 
    fprintf(stderr, "usage: mem <value>\n"); 
    exit(1); 
    } 
    int *p;                   // memory for pointer is on "stack"
    p = malloc(sizeof(int));  // malloc'd memory is on "heap"
    assert(p != NULL);
    printf("(pid:%d) addr of p:        %llx\n", (int) getpid(), 
       (unsigned long long) &p);
    printf("(pid:%d) addr stored in p: %llx\n", (int) getpid(), 
       (unsigned long long) p);
    *p = atoi(argv[1]);       // assign value to addr stored in p
    while (1) {
    Spin(1);
    *p = *p + 1;
    printf("(pid:%d) value of p: %d\n", getpid(), *p);
    }

    return 0;
}
```

一个访问内存的程序\(mem.c\) .

现在 , 让我们来考虑内存 . 现代化机器呈现的物理内存的模型是非常简单的 . 内存就是一个字节数组 . 读取内存 , 必须要一个指定地址能够访问存储在内存中数据 . 要写入\(更新\)内存 , 还需要将特定的数据写入到指定的地址 .

一个进程运行的所有时间内 , 内存都是可以被访问的 . 程序将它的所有数据结构都存放在内存中 , 并通过一系列指令来访问它们 , 就像在它们工作的时候 , 用载入,存储或者其他明确的指令访问内存 . 不要忘了每个指令也都是存放在内存中的 , 因此 , 在每个指令的取出时内存也是可以访问的 .

让我们来看看前面通过malloc\(\)函数分配内存的程序 . 这里是程序的输出 :

```
# 别忘记编译代码
./make-mem.csh
# 输出内容
➜  code.intro ./mem test
(pid:63018) addr of p:        7fff5fbffa28
(pid:63018) addr stored in p: 100100020
(pid:63018) value of p: 1
(pid:63018) value of p: 2
(pid:63018) value of p: 3
(pid:63018) value of p: 4
(pid:63018) value of p: 5
^C
```

这个程序做了几个事情 :

* 首先 , 它分配了一下内存 . 
* 然后 , 它打印了内存的地址 . 
* 接着将数字写入新分配的内存的最开始的位置 . 

最终进行循环 , 每隔一秒就将存储在指针指向的地址的数值增加 , 每次状态打印的时候 , 它也打印出来当前运行进程的进程标识符\(即PID\) . 这个PID就是该运行程序的特定标志 .

再次运行多个实例来看看发生了什么 :

```
prompt> ./mem &; ./mem &
[1] 24113
[2] 24114
(24113) memory address of p: 00200000
(24114) memory address of p: 00200000
(24113) p: 1
(24114) p: 1
(24114) p: 2
(24113) p: 2
(24113) p: 3
(24114) p: 3
(24113) p: 4
(24114) p: 4
...
```

这个例子中可以看到每个进程都是从相同的地址\(00200000\)开始分配内存 , 而且似乎是独立地去更新00200000处的数值的 . 似乎每个进程运行时 , 它们都拥有各自私有的内存 , 而不是与其他正在运行的进程共享相同的物理内存 .

实际上 , 操作系统中真正发生的事情是虚拟内存 . 每个进程都访问它们自己的私有的虚拟地址空间\(有时候就直接被称为地址空间\) , 操作系统将这些虚拟地址空间以某种方式映射到机器的物理内存 . 一个运行的程序引用的内存不会影响其他进程的地址空间\(或者操作系统本身\) , 就正在运行的程序而言 , 它独自占有所有的物理内存 . 然而 , 事实却是 , 物理内存是一个由操作系统管理的共享资源 . 这究竟是如何实现的也是本书第一部分的主体 , 虚拟化 . 

#### 并发

本书的另一个主题就是并发 . 我们通过这个概念来指代在同一个程序中一次性进行多个工作给主机带来而且必须得到解决的问题 . 并发的问题最初是操作系统自身范围内出现的 , 你可以从上面的例子中看到 , 操作系统同时做着许多事情 , 首先运行一个进程 , 然后另一个... . 事实证明 , 这样做带来了一些更深层次的而且很好玩的问题 . 

并发的问题已经不再仅仅局限于操作系统本身 , 现在的多线程程序也存在相同的问题 , 现在让我们来演示一个多线程程序 : 

```c
#include <stdio.h>
#include <stdlib.h>
#include "common_threads.h"

volatile int counter = 0; 
int loops;

void *worker(void *arg) {
    int i;
    for (i = 0; i < loops; i++) {
	counter = counter + 1;
    }
    pthread_exit(NULL);
}

int main(int argc, char *argv[]) {
    if (argc != 2) { 
	fprintf(stderr, "usage: threads <loops>\n"); 
	exit(1); 
    } 
    loops = atoi(argv[1]);
    pthread_t p1, p2;
    printf("Initial value : %d\n", counter);
    Pthread_create(&p1, NULL, worker, NULL); 
    Pthread_create(&p2, NULL, worker, NULL);
    Pthread_join(p1, NULL);
    Pthread_join(p2, NULL);
    printf("Final value   : %d\n", counter);
    return 0;
}
```



